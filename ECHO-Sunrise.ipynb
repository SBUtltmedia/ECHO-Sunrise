{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Sunrise logo | ![EEW logo](https://github.com/edgi-govdata-archiving/EEW-Image-Assets/blob/master/Jupyter%20instructions/eew.jpg?raw=true) | ![EDGI logo](https://github.com/edgi-govdata-archiving/EEW-Image-Assets/blob/master/Jupyter%20instructions/edgi.png?raw=true) |\n",
    "|---|---|---|\n",
    "\n",
    "#### This notebook is licensed under GPL 3.0. Please visit our Github repo for more information: https://github.com/edgi-govdata-archiving/ECHO-COVID19\n",
    "#### The notebook was collaboratively authored by EDGI following our authorship protocol: https://docs.google.com/document/d/1CtDN5ZZ4Zv70fHiBTmWkDJ9mswEipX6eCYrwicP66Xw/\n",
    "#### For more information about this project, visit https://www.environmentalenforcementwatch.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Run\n",
    "* A \"cell\" in a Jupyter notebook is a block of code performing a set of actions making available or using specific data.  The notebook works by running one cell after another, as the notebook user selects offered options.\n",
    "* If you click on a gray **code** cell, a little “play button” arrow appears on the left. If you click the play button, it will run the code in that cell (“**running** a cell”). The button will animate. When the animation stops, the cell has finished running.\n",
    "![Where to click to run the cell](https://github.com/edgi-govdata-archiving/EEW-Image-Assets/blob/master/Jupyter%20instructions/pressplay.JPG?raw=true)\n",
    "* You may get a warning that the notebook was not authored by Google. We know, we authored them! It’s okay. Click “Run Anyway” to continue. \n",
    "![Error Message](https://github.com/edgi-govdata-archiving/EEW-Image-Assets/blob/master/Jupyter%20instructions/warning-message.JPG?raw=true)\n",
    "* **It is important to run cells in order because they depend on each other.**\n",
    "* Run all of the cells in a Notebook to make a complete report. Please feel free to look at and **learn about each result as you create it**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Let's begin!** \n",
    "These first two cells give us access to some external Python code we will need. Hover over the \"[ ]\" on the top left corner of the cell below and you should see a \"play\" button appear. Click on it to run the cell then move to the next one.\n",
    "### 1.  Bring in some code that is stored in a Github project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/edgi-govdata-archiving/ECHO_modules.git\n",
    "!git clone https://github.com/edgi-govdata-archiving/ECHO-Geo.git\n",
    "!git clone -b first-draft --single-branch  https://github.com/edgi-govdata-archiving/ECHO-Sunrise.git # This has the utilities file for mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Run some external Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import code libraries\n",
    "%run ECHO_modules/DataSet.py\n",
    "%run ECHO-Sunrise/utilities.py \n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import csv\n",
    "import datetime\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What facilities does ECHO track in Mass?\n",
    "This may take some time to load - there are thousands of facilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo_data_sql = \"select * from ECHO_EXPORTER where FAC_STATE = 'MA' and FAC_ACTIVE_FLAG='Y' and GHG_FLAG='Y'\" # 24000 facilities in total, but can we load them all?\n",
    "\n",
    "try:\n",
    "    print(echo_data_sql)\n",
    "    echo_data = get_data( echo_data_sql, 'REGISTRY_ID' )\n",
    "    num_facilities = echo_data.shape[0]\n",
    "    print(\"\\nThere are %s EPA facilities in Massachussets tracked in the ECHO database.\" %(num_facilities))\n",
    "    #mapper_marker(echo_data) # Not showing up...\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"\\nThere are no EPA facilities in this region.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_marker(echo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Run this next cell to create to choose how you want to *zoom in*: what specific programs you want to look at and whether you want to view this information by county, congressional district or zip code.\n",
    "Here's where you can learn more about the different programs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ECHO_modules/make_data_sets.py\n",
    "\n",
    "# Only list the data set if it has the correct flag set.\n",
    "data_set_choices = []\n",
    "for k, v in data_sets.items():\n",
    "    if ( v.has_echo_flag( echo_data ) ):\n",
    "        data_set_choices.append( k )\n",
    "\n",
    "data_set_widget=widgets.Dropdown(\n",
    "    options=list(data_set_choices),\n",
    "    description='Data sets:',\n",
    "    disabled=False,\n",
    "    value='Greenhouse Gases'\n",
    ") \n",
    "display(data_set_widget)\n",
    "\n",
    "region_field = { \n",
    "    'Congressional District': { \"field\": 'FAC_DERIVED_CD113' },\n",
    "    'County': { \"field\": 'FAC_COUNTY' },\n",
    "    'Zip Code': { \"field\": 'FAC_DERIVED_ZIP' }\n",
    "}\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "select_region_widget = widgets.Dropdown(\n",
    "    options=region_field.keys(),\n",
    "    style=style,\n",
    "    value='County',\n",
    "    description='Region of interest:',\n",
    "    disabled=False\n",
    ")\n",
    "display( select_region_widget )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Here are all the facilities in this program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = data_sets[ data_set_widget.value ]\n",
    "program_data = None\n",
    "key=dict() # Create a way to look up Registry IDs in ECHO_EXPORTER later\n",
    "\n",
    "# We need to provide a custom list of program ids for some programs.\n",
    "if ( program.name == \"Air Inspections\" or program.name == \"Air Enforcements\" ):\n",
    "    # The REGISTRY_ID field is the index of the echo_data\n",
    "    registry_ids = echo_data[echo_data['AIR_FLAG'] == 'Y'].index.values\n",
    "    key = { i : i for i in registry_ids }\n",
    "    program_data = program.get_data( ee_ids=registry_ids )\n",
    "elif ( program.name == \"Combined Air Emissions\" ):\n",
    "    ghg_registry_ids = echo_data[echo_data['GHG_FLAG'] == 'Y'].index.values\n",
    "    tri_registry_ids = echo_data[echo_data['TRI_FLAG'] == 'Y'].index.values\n",
    "    id_set = np.union1d( ghg_registry_ids, tri_registry_ids )\n",
    "    registry_ids = list(id_set)\n",
    "    program_data = program.get_data( ee_ids=registry_ids )\n",
    "    key = { i : i for i in registry_ids }\n",
    "elif ( program.name == \"Greenhouse Gases\" or program.name == \"Toxic Releases\" ):\n",
    "    program_flag = program.echo_type + '_FLAG'\n",
    "    registry_ids = echo_data[echo_data[ program_flag ] == 'Y'].index.values\n",
    "    program_data = program.get_data( ee_ids=registry_ids )\n",
    "    key = { i : i for i in registry_ids }\n",
    "else:\n",
    "    ids_string = program.echo_type + '_IDS'\n",
    "    ids = list()\n",
    "    registry_ids = list()\n",
    "    for index, value in echo_data[ ids_string ].items():\n",
    "        try:\n",
    "            for this_id in value.split():\n",
    "                ids.append( this_id )\n",
    "                key[this_id]=index\n",
    "        except ( KeyError, AttributeError ) as e:\n",
    "            pass\n",
    "    program_data = program.get_data( ee_ids=ids )\n",
    "\n",
    "# Find the facility that matches the program data, by REGISTRY_ID.  \n",
    "# Add lat and lon, facility name and REGISTRY_ID as fac_registry_id. \n",
    "# (Note: not adding REGISTRY_ID right now as it is sometimes interpreted as an int and that messes with the charts...)\n",
    "my_prog_data = pd.DataFrame()\n",
    "no_data_ids = []\n",
    "\n",
    "# Look through all the facilities in my area and program and get supplemental echo_data info\n",
    "if (program_data is None): # Handle no data\n",
    "    print(\"Sorry, we don't have data for this program! That could be an error on our part, or ECHO's, or because the data type doesn't apply to this area.\")\n",
    "else:\n",
    "    for fac in program_data.itertuples():\n",
    "        fac_id = fac.Index\n",
    "        reg_id = key[fac_id] # Look up this facility's Registry ID through its Program ID\n",
    "        try:\n",
    "            echo_row = pd.DataFrame(echo_data.loc[reg_id].copy()).T.reset_index() # Find and filter to the corresponding row in ECHO_EXPORTER\n",
    "            echo_row = echo_row[['FAC_NAME', 'FAC_LAT', 'FAC_LONG']] # Keep only the columns we need\n",
    "            program_row =  pd.DataFrame([list(fac)[1:]], columns=program_data.columns.values) # Turn the program_data tuple into a DataFrame\n",
    "            full_row = pd.concat([program_row, echo_row], axis=1) # Join the EE row df and the program row df\n",
    "            frames = [my_prog_data, full_row]\n",
    "            my_prog_data = pd.concat( frames, ignore_index=False)\n",
    "        except KeyError:\n",
    "            # The facility wasn't found in the program data.\n",
    "            no_data_ids.append( fac.Index )\n",
    "\n",
    "# in ordert to map, roll up my_prog_data to facility level\n",
    "fac = my_prog_data.drop_duplicates(subset=['PGM_SYS_ID']) # or whatever the key is\n",
    "map_of_facilities = mapper_marker(fac)\n",
    "map_of_facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Here are the geographies we're going to summarize this information at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and map geojson for the selected geography\n",
    "geo = \"county\" #select_region_widget.value.lower()\n",
    "geo_json_data = geopandas.read_file(\"ECHO-Geo/ma_\"+geo+\".geojson\")\n",
    "\n",
    "m = folium.Map(\n",
    "    #tiles='Mapbox Bright',\n",
    ")\n",
    "folium.GeoJson(\n",
    "    geo_json_data,\n",
    ").add_to(m)\n",
    "\n",
    "bounds = m.get_bounds()\n",
    "m.fit_bounds(bounds)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Now we bring the geographic data and the facility data together. First, let's rank each geography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, spatialize my_prog_data\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    my_prog_data, geometry=geopandas.points_from_xy(my_prog_data[\"FAC_LONG\"], my_prog_data[\"FAC_LAT\"]))\n",
    "\n",
    "join = geopandas.sjoin(gdf, geo_json_data, how=\"inner\", op='intersects')\n",
    "\n",
    "# get geo and attribute data column names\n",
    "geo_column = {\"county\": \"COUNTY\"} # EXPAND\n",
    "att_column = {\"Greenhouse Gases\": \"ANNUAL_EMISSION\"} # EXPAND\n",
    "g = geo_column[geo]\n",
    "a = att_column[program.name]\n",
    "\n",
    "test = join.groupby(join[g])[[a]].agg(\"sum\")\n",
    "test.sort_values(by=a, ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Now, let's map it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(inplace=True)\n",
    "att_data = test.rename(columns={g: \"geo\", a: \"value\"}) \n",
    "mp = mapper_area(geo_json_data, att_data, g)\n",
    "mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Rank individual facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = my_prog_data.groupby([\"PGM_SYS_ID\", \"FAC_NAME\", \"FAC_LAT\", \"FAC_LONG\"])[[a]].agg(\"sum\")\n",
    "ranked.reset_index(inplace=True)\n",
    "ranked = ranked.set_index(\"PGM_SYS_ID\")\n",
    "ranked.sort_values(by=a, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Map individual facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked['quantile'] = pd.qcut(ranked[a], 4, labels=False)\n",
    "mp = mapper_circle(ranked)\n",
    "mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
